# -*- coding: utf-8 -*-
"""MNIST Digit Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cNz3mn01rvzFNtlRCXB1Sv_ggnuIZUhk

Importing the dependencies
"""

import numpy as np # for numpy array
import matplotlib.pyplot as plt # for plot and visualization
import seaborn as sns # for graphs
import cv2 # opencv library for image processing
from google.colab.patches import cv2_imshow  #for displaying the image
from PIL import Image # for image processing task
import tensorflow as tf # Deep learning library
tf.random.set_seed(3) #The purpose of setting the seed is that when we are training a neural network and feeding data into it, several values are generated randomly during the learning process. Because of this randomness, each time we train the neural network—even with the same data—the accuracy and other results may vary slightly. By setting the random seed to a specific number, we ensure that these random values are generated in the same way every time, making the results consistent across runs.
from tensorflow import keras
from keras.datasets import mnist
from tensorflow.math import confusion_matrix

"""LOading the MNIST data from keras.datasets"""

(X_train, Y_train), (X_test, Y_test) = mnist.load_data()

type(X_train)

#shape of the numpy arrays
print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)

"""Training Data ----> 60000 Images

Test Data ----> 10000 Images

Training Data ----> 28 * 28

Grayscale Image ----> 1 channel
"""

#printing the 10th image
print(X_train[10])

print(X_train[10].shape)

#display the image
plt.imshow(X_train[20])
plt.show()

#printing the corresponding label
print(Y_train[20])

"""Image Labels"""

print(Y_train.shape, Y_test.shape)

#unique values in Y_train
print(np.unique(Y_train))

#unique values in Y_test
print(np.unique(Y_test))

"""we can use these labels as such or we can also apply one hot encoding

All the images have the same dimensions in this datset. If not we have to resize all the images to a common dimensions
"""

#scaling the values
X_train = X_train/255
X_test = X_test/255

"""0/255 = 0

255/255 = 1
"""

#printing the 10th image
print(X_train[10])

"""Building the neural networks"""

# setting up the layer of the neural network

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)), # input layer 1  # instead of having rows and columns all the values will be loaded as a single line. Here (28, 28- Image dimension)
    keras.layers.Dense(50, activation='relu'), # hidden layer 1 # Dense - all the layers in this particular neural network is connected to the neurons in the previous and the next layer
    keras.layers.Dense(50, activation='relu'), # hidden layer 2
    keras.layers.Dense(10, activation='sigmoid') # output layer
])

# Compiling the Neural Network
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy']) #Optimizers purpose - to get the optimal parameters, loss function ('sparse_categorical_crossentropy'- when we will convert the labels into encoded labels we require this, accuracy - the no. of correct prediction divided by the total number of data points we add

# training the neural network

model.fit(X_train, Y_train, epochs=10) # epoch is how many times neural network should go through the data, each time it will try to its parameter value and it will try to give its accuracy

"""Training data accuracy is 99.01%

Accuracy on test data:
"""

loss, accuracy = model.evaluate(X_test, Y_test)
print(accuracy)

"""Test data accuracy is 96.8%"""

print (X_test.shape)

#first data point in X_test
plt.imshow(X_test[0])
plt.show()

print(Y_test[0])

Y_pred = model.predict(X_test)

print(Y_pred.shape)

print(Y_pred[0])

"""model.predict() gives the prediction probability of each class for the data point"""

#converting the prediction probabilites to class label
label_for_first_test_image = np.argmax(Y_pred[0])
print(label_for_first_test_image)

#converting the prediction probabilites to class label for all the test data points
Y_pred_labels = [np.argmax(i) for i in Y_pred]
print(Y_pred_labels)

"""Y_test --> True labels

Y_pred_labels --> Predicted labels

Confusion Matrix
"""

conf_mat = confusion_matrix(Y_test, Y_pred_labels)
print(conf_mat)

plt.figure(figsize = (15,7))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.ylabel('True Labels')
plt.xlabel('Predicted Labels')

"""Building a predictive system"""

input_image_path = '/content/MNIST_digit.png'

input_image = cv2.imread(input_image_path)

type(input_image)

print(input_image)

print(input_image.shape)

cv2_imshow(input_image)

# Converting the image to grayscale image
grayscale_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)

grayscale_image.shape

# Resizing the dimension of the image
input_image_resize = cv2.resize(grayscale_image, (28,28))

input_image_resize.shape

cv2_imshow(input_image_resize)

input_image_resize = input_image_resize/255

type(input_image_resize)

image_reshaped = np.reshape(input_image_resize, [1,28,28])

input_prediction = model.predict(image_reshaped)
print(input_prediction)

input_pred_label = np.argmax(input_prediction)

print(input_pred_label)

"""Predictive System"""

input_image_path = input('Enter the path of the image to be predicted: ')

input_image = cv2.imread(input_image_path)

cv2_imshow(input_image)

grayscale_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)

input_image_resize = cv2.resize(grayscale_image, (28,28))

input_image_resize = input_image_resize/255

image_reshaped = np.reshape(input_image_resize, [1,28,28])

input_prediction = model.predict(image_reshaped)

input_pred_label = np.argmax(input_prediction)

print('The Handwritten Digit is recognised as ', input_pred_label)

